{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f72b97f3",
   "metadata": {},
   "source": [
    "## First Autogen Agent\n",
    "The main objective of this project is to build a simple agent using **AutoGen v0.4** and **OpenAI's GPT-4**.  \n",
    "We'll ask the agent fun question and see how it responds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "364b46ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent # handles the logic and orchestration\n",
    "\"\"\"\n",
    "1. Interacts with users or other agents\n",
    "2. Uses an LLM (like GPT-4) to generate responses\n",
    "3. Can call tools, hand off tasks, and manage multi-step workflows\n",
    "4. Supports memory, streaming, and structured output\n",
    "\"\"\"\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient # provides the language model backend\n",
    "\"\"\"\n",
    "1. Sending messages to the model\n",
    "2. Receiving responses\n",
    "3. Streaming tokens (if enabled)\n",
    "4. Structured output (via Pydantic schemas)\n",
    "5. Tool calling and function execution\n",
    "\"\"\"\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv('OPEN_AI_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c69d586",
   "metadata": {},
   "source": [
    "### Connecting to the Model\n",
    "We use **OpenAIChatCompletionClient** to link our agent to GPT-4.  \n",
    "In v0.4 this replaces the older **llm-config** approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a311792",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelClient = OpenAIChatCompletionClient(model='gpt-3.5-turbo', api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18e05fe",
   "metadata": {},
   "source": [
    "### Building the Agent\n",
    "The **AssistantAgent** is a conversational AI that can respond to tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3dba012e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = AssistantAgent(name = 'assist', model_client=modelClient)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4716fa",
   "metadata": {},
   "source": [
    "### Testing the Agent\n",
    "We'll use the **run** method for getting a response (a simple way in v0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c6cc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await assistant.run(task=\"Tell me a fact about Arsenal FC\")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1417c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.messages[-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcdadd1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
